# è‡ªé€‚åº”æ‹“æ‰‘ç³»ç»Ÿå®‰è£…å’Œä½¿ç”¨æŒ‡å—

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒè¦æ±‚

- **Python**: 3.8+
- **æ“ä½œç³»ç»Ÿ**: Linux, macOS, Windows
- **å†…å­˜**: è‡³å°‘ 2GB å¯ç”¨å†…å­˜
- **GPU**: å¯é€‰ï¼Œç”¨äºåŠ é€Ÿæ·±åº¦å­¦ä¹ è®­ç»ƒ

### 2. å®‰è£…ä¾èµ–

#### æ–¹æ³•ä¸€ï¼šä½¿ç”¨è¿œç¨‹æœåŠ¡å™¨ï¼ˆæ¨èï¼‰

å¦‚æœæ‚¨çš„æœ¬åœ°ç¯å¢ƒæ²¡æœ‰PyTorchï¼Œå¯ä»¥ä½¿ç”¨VSCodeçš„Remote SSHæ’ä»¶è¿æ¥åˆ°æœ‰PyTorchçš„æœåŠ¡å™¨ï¼š

```bash
# åœ¨è¿œç¨‹æœåŠ¡å™¨ä¸Š
cd /path/to/agno
pip install -r libs/agno/requirements-topology.txt
```

#### æ–¹æ³•äºŒï¼šæœ¬åœ°å®‰è£…

```bash
# å®‰è£…PyTorch (æ ¹æ®æ‚¨çš„ç³»ç»Ÿé€‰æ‹©)
# CPUç‰ˆæœ¬
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu

# GPUç‰ˆæœ¬ (CUDA 11.8)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# å®‰è£…å…¶ä»–ä¾èµ–
pip install -r libs/agno/requirements-topology.txt

# å®‰è£…agno (å¼€å‘æ¨¡å¼)
cd libs/agno
pip install -e .
```

### 3. éªŒè¯å®‰è£…

```bash
python -c "import torch; print('PyTorch version:', torch.__version__)"
python -c "from agno.topology.types import TopologyType; print('Topology types loaded successfully')"
```

## ğŸ“‹ é…ç½®è®¾ç½®

### 1. åˆ›å»ºé…ç½®æ–‡ä»¶

```bash
cd /path/to/agno
python -c "from agno.topology.config import ConfigManager; ConfigManager().create_sample_config()"
```

è¿™å°†åˆ›å»º `topology_config_sample.json` æ–‡ä»¶ã€‚

### 2. è‡ªå®šä¹‰é…ç½®

å°† `topology_config_sample.json` é‡å‘½åä¸º `topology_config.json` å¹¶æ ¹æ®éœ€è¦ä¿®æ”¹ï¼š

```json
{
  "environment": "production",
  "debug_mode": false,
  "log_level": "INFO",
  "max_agents_per_team": 10,
  "max_concurrent_teams": 5,
  "adaptation_config": {
    "min_efficiency_threshold": 0.65,
    "adaptation_cooldown": 60.0,
    "prefer_gnn": true,
    "enable_rl_learning": true
  }
}
```

### 3. ç¯å¢ƒå˜é‡

è®¾ç½®å¿…è¦çš„ç¯å¢ƒå˜é‡ï¼š

```bash
# OpenAI APIå¯†é’¥ï¼ˆå¦‚æœä½¿ç”¨OpenAIæ¨¡å‹ï¼‰
export OPENAI_API_KEY="your-api-key-here"

# é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
export AGNO_TOPOLOGY_CONFIG="/path/to/topology_config.json"
```

## ğŸƒâ€â™‚ï¸ è¿è¡Œç¤ºä¾‹

### 1. ç”Ÿäº§ç¯å¢ƒç¤ºä¾‹

```bash
cd /path/to/agno
python examples/production_topology_example.py
```

è¿™ä¸ªç¤ºä¾‹å±•ç¤ºäº†ï¼š
- âœ… çœŸå®çš„æ€§èƒ½ç›‘æ§
- âœ… èµ„æºç®¡ç†å’Œé™åˆ¶
- âœ… æ‹“æ‰‘è‡ªåŠ¨é€‚åº”
- âœ… é”™è¯¯å¤„ç†å’Œæ¢å¤
- âœ… ç”Ÿäº§çº§æ—¥å¿—è®°å½•

### 2. åŸºç¡€é›†æˆç¤ºä¾‹

```python
import asyncio
from agno.agent import Agent
from agno.team import Team
from agno.models.openai import OpenAIChat
from agno.topology.production_manager import ProductionTopologyManager

async def basic_example():
    # åˆ›å»ºæ™ºèƒ½ä½“
    agent1 = Agent(
        name="Researcher",
        agent_id="researcher_001",
        model=OpenAIChat(id="gpt-4o-mini")
    )
    
    agent2 = Agent(
        name="Analyst", 
        agent_id="analyst_001",
        model=OpenAIChat(id="gpt-4o-mini")
    )
    
    # åˆ›å»ºå›¢é˜Ÿ
    team = Team(
        name="Research Team",
        team_id="team_001",
        members=[agent1, agent2],
        mode="coordinate"
    )
    
    # åˆ›å»ºæ‹“æ‰‘ç®¡ç†å™¨
    manager = ProductionTopologyManager()
    await manager.start()
    
    # æ³¨å†Œå›¢é˜Ÿ
    success = manager.register_team(
        team=team,
        task_description="Research task",
        complexity=0.6
    )
    
    if success:
        print("âœ… Team registered successfully")
        
        # æ‰§è¡Œä»»åŠ¡
        async def research_task():
            # è¿™é‡Œæ”¾ç½®æ‚¨çš„å®é™…ä»»åŠ¡é€»è¾‘
            await asyncio.sleep(2)
            return "Research completed"
        
        result = await manager.execute_task(
            team_id=team.team_id,
            task_description="AI research",
            task_function=research_task,
            complexity=0.7
        )
        
        print(f"Task result: {result}")
    
    await manager.stop()

# è¿è¡Œç¤ºä¾‹
asyncio.run(basic_example())
```

## ğŸ”§ é«˜çº§é…ç½®

### 1. è‡ªå®šä¹‰æ‹“æ‰‘é€‚åº”ç­–ç•¥

```python
from agno.topology.adaptive import AdaptationConfig

# åˆ›å»ºè‡ªå®šä¹‰é€‚åº”é…ç½®
adaptation_config = AdaptationConfig(
    min_efficiency_threshold=0.7,        # æ›´é«˜çš„æ•ˆç‡è¦æ±‚
    adaptation_cooldown=30.0,            # æ›´é¢‘ç¹çš„é€‚åº”
    prefer_gnn=True,                     # ä¼˜å…ˆä½¿ç”¨GNN
    enable_rl_learning=True,             # å¯ç”¨å¼ºåŒ–å­¦ä¹ 
    max_communication_cost_threshold=0.6  # æ›´ä¸¥æ ¼çš„é€šä¿¡æˆæœ¬æ§åˆ¶
)
```

### 2. è‡ªå®šä¹‰GNNé…ç½®

```python
from agno.topology.gnn_generator import GNNConfig

gnn_config = GNNConfig(
    hidden_dim=256,      # æ›´å¤§çš„éšè—å±‚
    num_layers=4,        # æ›´æ·±çš„ç½‘ç»œ
    learning_rate=0.0005, # æ›´å°çš„å­¦ä¹ ç‡
    dropout=0.2          # æ›´é«˜çš„dropout
)
```

### 3. è‡ªå®šä¹‰RLé…ç½®

```python
from agno.topology.rl_search import RLConfig

rl_config = RLConfig(
    state_dim=256,       # æ›´å¤§çš„çŠ¶æ€ç©ºé—´
    action_dim=128,      # æ›´å¤§çš„åŠ¨ä½œç©ºé—´
    epsilon=0.05,        # æ›´å°‘çš„æ¢ç´¢
    batch_size=64,       # æ›´å¤§çš„æ‰¹æ¬¡
    buffer_size=50000    # æ›´å¤§çš„ç»éªŒå›æ”¾ç¼“å†²åŒº
)
```

## ğŸ“Š ç›‘æ§å’Œè°ƒè¯•

### 1. å¯ç”¨è¯¦ç»†æ—¥å¿—

```python
import logging

# è®¾ç½®è¯¦ç»†æ—¥å¿—
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

# æˆ–åœ¨é…ç½®æ–‡ä»¶ä¸­è®¾ç½®
{
  "log_level": "DEBUG",
  "debug_mode": true
}
```

### 2. æ€§èƒ½ç›‘æ§

ç³»ç»Ÿä¼šè‡ªåŠ¨æ”¶é›†ä»¥ä¸‹æŒ‡æ ‡ï¼š
- CPUå’Œå†…å­˜ä½¿ç”¨ç‡
- ä»»åŠ¡å®Œæˆæ—¶é—´
- æ‹“æ‰‘é€‚åº”é¢‘ç‡
- é€šä¿¡æˆæœ¬
- è´Ÿè½½å¹³è¡¡åº¦

ç›‘æ§æ•°æ®ä¿å­˜åœ¨ `./models/topology/metrics.json`

### 3. æ¨¡å‹æ£€æŸ¥ç‚¹

æ¨¡å‹ä¼šè‡ªåŠ¨ä¿å­˜æ£€æŸ¥ç‚¹ï¼š
- GNNæ¨¡å‹: `./models/topology/{team_id}/gnn_checkpoint_{timestamp}.pt`
- RLæ¨¡å‹: `./models/topology/{team_id}/rl_checkpoint_{timestamp}.pt`

## ğŸš¨ æ•…éšœæ’é™¤

### 1. å¸¸è§é—®é¢˜

**é—®é¢˜**: `ImportError: No module named 'torch'`
**è§£å†³**: å®‰è£…PyTorch
```bash
pip install torch torchvision torchaudio
```

**é—®é¢˜**: `CUDA out of memory`
**è§£å†³**: å‡å°‘æ‰¹æ¬¡å¤§å°æˆ–ä½¿ç”¨CPU
```python
# åœ¨é…ç½®ä¸­è®¾ç½®
{
  "gnn_config": {
    "batch_size": 16  # å‡å°‘æ‰¹æ¬¡å¤§å°
  }
}
```

**é—®é¢˜**: æ‹“æ‰‘é€‚åº”è¿‡äºé¢‘ç¹
**è§£å†³**: å¢åŠ å†·å´æ—¶é—´
```python
{
  "adaptation_config": {
    "adaptation_cooldown": 120.0  # 2åˆ†é’Ÿå†·å´
  }
}
```

### 2. æ€§èƒ½ä¼˜åŒ–

**å†…å­˜ä¼˜åŒ–**:
```python
{
  "max_memory_usage_mb": 1024,  # é™åˆ¶å†…å­˜ä½¿ç”¨
  "performance_history_size": 500  # å‡å°‘å†å²è®°å½•
}
```

**CPUä¼˜åŒ–**:
```python
{
  "max_cpu_usage_percent": 70.0,  # é™åˆ¶CPUä½¿ç”¨
  "adaptation_check_interval": 60.0  # å‡å°‘æ£€æŸ¥é¢‘ç‡
}
```

## ğŸ”— é›†æˆåˆ°ç°æœ‰é¡¹ç›®

### 1. æœ€å°é›†æˆ

```python
from agno.topology.manager import TopologyManager

# åœ¨ç°æœ‰å›¢é˜Ÿä¸­å¯ç”¨è‡ªé€‚åº”æ‹“æ‰‘
topology_manager = TopologyManager()
topology_manager.register_team(your_existing_team)
topology_manager.start()

# åœ¨ä»»åŠ¡æ‰§è¡Œå‰æ›´æ–°çŠ¶æ€
topology_manager.update_task_state(
    team_id=your_team.team_id,
    complexity=task_complexity,
    urgency=task_urgency
)
```

### 2. å®Œæ•´é›†æˆ

å‚è€ƒ `examples/production_topology_example.py` ä¸­çš„å®Œæ•´ç¤ºä¾‹ã€‚

## ğŸ“š APIå‚è€ƒ

è¯¦ç»†çš„APIæ–‡æ¡£è¯·å‚è€ƒï¼š
- [TopologyManager API](libs/agno/agno/topology/manager.py)
- [ProductionTopologyManager API](libs/agno/agno/topology/production_manager.py)
- [é…ç½®é€‰é¡¹](libs/agno/agno/topology/config.py)

## ğŸ¤ è´¡çŒ®

å¦‚æœæ‚¨æƒ³ä¸ºè‡ªé€‚åº”æ‹“æ‰‘ç³»ç»Ÿåšå‡ºè´¡çŒ®ï¼š

1. Fork é¡¹ç›®
2. åˆ›å»ºåŠŸèƒ½åˆ†æ”¯
3. æ·»åŠ æµ‹è¯•
4. æäº¤ Pull Request

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®éµå¾ª agno æ¡†æ¶çš„è®¸å¯è¯æ¡æ¬¾ã€‚
